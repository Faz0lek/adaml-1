{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intel sensors level A2\n",
    "\n",
    "Authors: Martin KostelnÃ­k, Marianne Jakonen, Ahmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import helper\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Define some paths\n",
    "DATA_PATH = r\"../data/data.txt.gz\"\n",
    "DATA_PROCESSED_PATH = r\"../data/data_processed.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let's get the data\n",
    "# I preprocessed the data and saved it for faster loading\n",
    "\n",
    "# Load raw data\n",
    "# data_raw = helper.load_data(DATA_PATH)\n",
    "\n",
    "# Preprocess data\n",
    "# data = helper.preprocess_data(data_raw)\n",
    "# data.to_csv(\"data_resampled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H-26    92.736138\n",
       "H-30    92.091317\n",
       "H-31    91.160904\n",
       "H-27    90.419350\n",
       "H-29    89.718965\n",
       "          ...    \n",
       "T-38    44.422759\n",
       "L-46    43.764384\n",
       "H-53    39.741264\n",
       "T-35    36.455761\n",
       "T-6     32.416700\n",
       "Length: 156, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load processed data\n",
    "df = pd.read_csv(DATA_PROCESSED_PATH)\n",
    "df[\"datetime\"] = pd.to_datetime(df[\"datetime\"])\n",
    "\n",
    "# Find the most correlated variable\n",
    "correlation = df.corr(numeric_only=True).abs().sum().sort_values(ascending=False)\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most correlated variable is humidity of a sensor number 26.\n",
    "Let's take it out of a dataframe as it is the variable we will make predictions for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.3.2004 is Monday, let's start from that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array 0.2576987471000135 cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [73], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m         pls\u001b[39m.\u001b[39mfit(X_train, Y_train)\n\u001b[0;32m     33\u001b[0m         Y_pred \u001b[39m=\u001b[39m pls\u001b[39m.\u001b[39mpredict(np\u001b[39m.\u001b[39marray(X_test)\u001b[39m.\u001b[39mreshape(\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n\u001b[1;32m---> 35\u001b[0m         r2 \u001b[39m=\u001b[39m r2_score(Y_test\u001b[39m.\u001b[39;49msqueeze(), Y_pred\u001b[39m.\u001b[39;49msqueeze())\n\u001b[0;32m     36\u001b[0m         r2s[day, n_comps] \u001b[39m=\u001b[39m r2\n\u001b[0;32m     38\u001b[0m r2s\n",
      "File \u001b[1;32md:\\Projects\\LUT\\advanced-data-analysis-ML\\project\\winvenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:911\u001b[0m, in \u001b[0;36mr2_score\u001b[1;34m(y_true, y_pred, sample_weight, multioutput, force_finite)\u001b[0m\n\u001b[0;32m    784\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mr2_score\u001b[39m(\n\u001b[0;32m    785\u001b[0m     y_true,\n\u001b[0;32m    786\u001b[0m     y_pred,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    790\u001b[0m     force_finite\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m    791\u001b[0m ):\n\u001b[0;32m    792\u001b[0m     \u001b[39m\"\"\":math:`R^2` (coefficient of determination) regression score function.\u001b[39;00m\n\u001b[0;32m    793\u001b[0m \n\u001b[0;32m    794\u001b[0m \u001b[39m    Best possible score is 1.0 and it can be negative (because the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[39m    -inf\u001b[39;00m\n\u001b[0;32m    910\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 911\u001b[0m     y_type, y_true, y_pred, multioutput \u001b[39m=\u001b[39m _check_reg_targets(\n\u001b[0;32m    912\u001b[0m         y_true, y_pred, multioutput\n\u001b[0;32m    913\u001b[0m     )\n\u001b[0;32m    914\u001b[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[0;32m    916\u001b[0m     \u001b[39mif\u001b[39;00m _num_samples(y_pred) \u001b[39m<\u001b[39m \u001b[39m2\u001b[39m:\n",
      "File \u001b[1;32md:\\Projects\\LUT\\advanced-data-analysis-ML\\project\\winvenv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:100\u001b[0m, in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_reg_targets\u001b[39m(y_true, y_pred, multioutput, dtype\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m     67\u001b[0m     \u001b[39m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \n\u001b[0;32m     69\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[39m        correct keyword.\u001b[39;00m\n\u001b[0;32m     99\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 100\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[0;32m    101\u001b[0m     y_true \u001b[39m=\u001b[39m check_array(y_true, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m    102\u001b[0m     y_pred \u001b[39m=\u001b[39m check_array(y_pred, ensure_2d\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, dtype\u001b[39m=\u001b[39mdtype)\n",
      "File \u001b[1;32md:\\Projects\\LUT\\advanced-data-analysis-ML\\project\\winvenv\\lib\\site-packages\\sklearn\\utils\\validation.py:384\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_consistent_length\u001b[39m(\u001b[39m*\u001b[39marrays):\n\u001b[0;32m    374\u001b[0m     \u001b[39m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \n\u001b[0;32m    376\u001b[0m \u001b[39m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m     lengths \u001b[39m=\u001b[39m [_num_samples(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m arrays \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m    385\u001b[0m     uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32md:\\Projects\\LUT\\advanced-data-analysis-ML\\project\\winvenv\\lib\\site-packages\\sklearn\\utils\\validation.py:384\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    373\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcheck_consistent_length\u001b[39m(\u001b[39m*\u001b[39marrays):\n\u001b[0;32m    374\u001b[0m     \u001b[39m\"\"\"Check that all arrays have consistent first dimensions.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m \n\u001b[0;32m    376\u001b[0m \u001b[39m    Checks whether all objects in arrays have the same shape or length.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    381\u001b[0m \u001b[39m        Objects that will be checked for consistent length.\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m     lengths \u001b[39m=\u001b[39m [_num_samples(X) \u001b[39mfor\u001b[39;00m X \u001b[39min\u001b[39;00m arrays \u001b[39mif\u001b[39;00m X \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m]\n\u001b[0;32m    385\u001b[0m     uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    386\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32md:\\Projects\\LUT\\advanced-data-analysis-ML\\project\\winvenv\\lib\\site-packages\\sklearn\\utils\\validation.py:325\u001b[0m, in \u001b[0;36m_num_samples\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    323\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m x\u001b[39m.\u001b[39mshape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    324\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(x\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m--> 325\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    326\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mSingleton array \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m cannot be considered a valid collection.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m x\n\u001b[0;32m    327\u001b[0m         )\n\u001b[0;32m    328\u001b[0m     \u001b[39m# Check that shape is returning an integer or default to len\u001b[39;00m\n\u001b[0;32m    329\u001b[0m     \u001b[39m# Dask dataframes may not return numeric shape[0] value\u001b[39;00m\n\u001b[0;32m    330\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(x\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], numbers\u001b[39m.\u001b[39mIntegral):\n",
      "\u001b[1;31mTypeError\u001b[0m: Singleton array 0.2576987471000135 cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/17315737/split-a-large-pandas-dataframe\n",
    "def split_dataframe(df, chunk_size):\n",
    "    chunks = list()\n",
    "    num_chunks = len(df) // chunk_size + 1\n",
    "    for i in range(num_chunks):\n",
    "        chunks.append(df[i*chunk_size:(i+1)*chunk_size])\n",
    "    return chunks\n",
    "\n",
    "r2s = np.zeros((7, 10))\n",
    "\n",
    "for n_comps in range(1, 11):\n",
    "    for day in range(1, 8):\n",
    "        X = df[df[\"datetime\"].dt.date == pd.to_datetime(f\"2004-03-0{day}\")].loc[:, df.columns != \"H-26\"].drop(columns=[\"datetime\"])\n",
    "        Y = df[df[\"datetime\"].dt.date == pd.to_datetime(f\"2004-03-0{day}\")][\"H-26\"]\n",
    "\n",
    "        X_train = X.iloc[:-1, :]\n",
    "        X_test = X.iloc[-1]\n",
    "        Y_train = Y.iloc[:-1]\n",
    "        Y_test = Y.iloc[-1]\n",
    "\n",
    "        X_train_mean = X_train.mean()\n",
    "        X_train_std = X_train.std()\n",
    "        Y_train_mean = Y_train.mean()\n",
    "        Y_train_std = Y_train.std()\n",
    "\n",
    "        X_train = (X_train - X_train_mean) / X_train_std\n",
    "        X_test = (X_test - X_train_mean) / X_train_std\n",
    "        Y_train = (Y_train - Y_train_mean) / Y_train_std\n",
    "        Y_test = (Y_test - Y_train_mean) / Y_train_std\n",
    "\n",
    "        pls = PLSRegression(n_components = n_comps)\n",
    "        pls.fit(X_train, Y_train)\n",
    "        Y_pred = pls.predict(np.array(X_test).reshape(1, -1))\n",
    "\n",
    "        r2 = r2_score(Y_test.squeeze(), Y_pred.squeeze())\n",
    "        r2s[day, n_comps] = r2\n",
    "\n",
    "r2s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 ('winvenv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c4f1a7139b336c062174acfa7d8426b73318a5ad625e4124c6794dde4ab23e94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
